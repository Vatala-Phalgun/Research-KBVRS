{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62f3d9-1d65-4c43-a03e-66458c6ea9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d8848-4279-4e24-bf5b-870b2d23d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the videos\n",
    "video_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Video'\n",
    "\n",
    "# Define the parent directory where the audio and transcriptions will be stored\n",
    "parent_audio_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL'\n",
    "\n",
    "# Define the reference text for similarity calculation\n",
    "input_text = \"linear regression\"  \n",
    "\n",
    "# Load pre-trained Wav2Vec2 model and processor\n",
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b70f6d-70ce-477e-afbe-43eafb7d9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert video to audio\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee49ee0-4828-41a7-ad99-da852dd936b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe audio chunks\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9966cd-3422-495a-982f-3a4c7df2c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe audio in parallel\n",
    "def transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d5879c-c331-47aa-b306-f0f443b605b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to optimize transcribed text\n",
    "def optimize_text(text):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    words = word_tokenize(text)a\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a0350-3fa1-4317-9d96-69c91e4b199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correct spelling errors\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling errors in the text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "    filtered_words = text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490b61f-264d-4c1f-acfc-370a881bd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8cce5-a83e-457d-84b0-c7be88087d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Define the directory containing the videos\n",
    "video_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Video'\n",
    "\n",
    "# Define the parent directory where the audio and transcriptions will be stored\n",
    "parent_audio_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL'\n",
    "\n",
    "# Define the reference text for similarity calculation\n",
    "input_text = \"linear regression\"  \n",
    "\n",
    "# Load pre-trained Wav2Vec2 model and processor\n",
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Function to convert video to audio\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "# Function to transcribe audio chunks\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription\n",
    "\n",
    "# Function to transcribe audio in parallel\n",
    "def transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "# Function to optimize transcribed text\n",
    "def optimize_text(text):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    words = word_tokenize(text)a\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Function to correct spelling errors\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling errors in the text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "    filtered_words = text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b0046-e71b-4bf2-870b-37cf92931afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Convert video to audio\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            audio_directory = os.path.join(parent_audio_directory, 'audio_KBVRS', os.path.splitext(video_file)[0])\n",
    "            audio_path = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '.wav')\n",
    "            transcription_file = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '_transcription.txt')\n",
    "\n",
    "            # Check if transcription directory already exists\n",
    "            if not os.path.exists(audio_directory):\n",
    "                os.makedirs(audio_directory)\n",
    "\n",
    "                # Convert video to audio\n",
    "                convert_video_to_audio(video_path, audio_path)\n",
    "\n",
    "    # Transcribe audio\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            audio_directory = os.path.join(parent_audio_directory, 'audio_KBVRS', os.path.splitext(video_file)[0])\n",
    "            audio_path = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '.wav')\n",
    "            transcription_file = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '_transcription.txt')\n",
    "\n",
    "            # Check if transcription file already exists\n",
    "            if not os.path.exists(transcription_file):\n",
    "                # Transcribe audio\n",
    "                transcriptions = transcribe_audio_parallel(audio_path, wav2vec2_processor, wav2vec2_model)\n",
    "                transcriptions_text = \"\".join(transcriptions)\n",
    "\n",
    "                # Write transcribed text to file\n",
    "                with open(transcription_file, \"w\") as file:\n",
    "                    file.write(transcriptions_text)\n",
    "\n",
    "                # Optimize text and correct spelling\n",
    "                optimized_text = optimize_text(transcriptions_text)\n",
    "                corrected_text = correct_spelling(optimized_text)\n",
    "\n",
    "                # Calculate cosine similarity\n",
    "                cosine_sim = calculate_cosine_similarity(corrected_text, input_text)\n",
    "\n",
    "                print(f\"Video: {video_file}, Cosine Similarity: {cosine_sim}\")\n",
    "\n",
    "                # Hide the directory\n",
    "                if os.name == 'nt':  # Windows\n",
    "                    ctypes.windll.kernel32.SetFileAttributesW(audio_directory, 2)  # 2 is the code for hidden attribute\n",
    "                else:  # Unix-like\n",
    "                    os.rename(audio_directory, os.path.join(os.path.dirname(audio_directory), '.' + os.path.basename(audio_directory)))\n",
    "            else:\n",
    "                print(f\"Transcription file already exists for {video_file}. Skipping transcription.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
