{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ce1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of pipeline\n",
    "\n",
    "Modules : Moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d8ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion from vid to wav : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Path to the input video file\n",
    "input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\n",
    "\n",
    "\n",
    "# Path to the output audio file\n",
    "output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\n",
    "\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(input_video_path)\n",
    "\n",
    "# Extract audio from the video clip\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Write the audio to a WAV file\n",
    "audio_clip.write_audiofile(output_audio_path)\n",
    "\n",
    "# Close the video clip\n",
    "video_clip.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fea89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using wav2vec2 for audio transcribing : loading wav , training , saving\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "\n",
    "# Load pre-trained Wav2Vec2 model and processor\n",
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Load audio file\n",
    "audio_file_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Audio\\01.wav'\n",
    "\n",
    "# Transcribe audio in batches using Wav2Vec2\n",
    "def transcribe_audio_batch(audio_file_path, batch_size=10, chunk_size=5, interval=10):\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "\n",
    "    # Split audio into chunks\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    # Process chunks in batches\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "\n",
    "        input_values = wav2vec2_processor(batch, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "        logits = wav2vec2_model(input_values).logits\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        batch_transcriptions = wav2vec2_processor.batch_decode(predicted_ids)\n",
    "\n",
    "        transcriptions.extend(batch_transcriptions)\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "# Transcribe audio in batches and save to a .txt file\n",
    "transcriptions = transcribe_audio_batch(audio_file_path)\n",
    "print(\"Transcriptions:\", transcriptions)\n",
    "\n",
    "# Filter out empty strings from transcriptions\n",
    "transcriptions = [transcription.strip() for transcription in transcriptions if transcription.strip()]\n",
    "\n",
    "# Join transcriptions into a single string without spaces between words\n",
    "transcriptions_text = \"\".join(transcriptions)\n",
    "\n",
    "# Save transcriptions to a .txt file\n",
    "output_file = \"transcriptions2.txt\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(transcriptions_text)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15575e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered text saved to: transcriptions2_test1.txt\n"
     ]
    }
   ],
   "source": [
    "#Optimizing the transcribed text , removing filler words \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the transcribed text from the file\n",
    "file_path = 'transcriptions2.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Define a set of stopwords\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# Remove punctuation from string.punctuation\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Combine all stopwords\n",
    "all_stopwords = english_stopwords.union(punctuation)\n",
    "\n",
    "# Remove stopwords and punctuation\n",
    "filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "\n",
    "# Join the filtered words back into a string\n",
    "filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "# Save the filtered text to a new file\n",
    "output_file_path = 'transcriptions2_test1.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(filtered_text)\n",
    "\n",
    "print(\"Filtered text saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3ab8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected text saved to: transcriptions2_corrected_test1.txt\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Initialize the spellchecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "# Open the file with filtered text without stopwords\n",
    "filtered_text_file_path = 'transcriptions2.txt'\n",
    "with open(filtered_text_file_path, 'r') as file:\n",
    "    filtered_text = file.read()\n",
    "\n",
    "# Tokenize the filtered text into words\n",
    "filtered_words = filtered_text.split()\n",
    "\n",
    "# Correct each word using spellchecker\n",
    "corrected_words = []\n",
    "for word in filtered_words:\n",
    "    corrected_word = spell.correction(word)\n",
    "    if corrected_word is not None:\n",
    "        corrected_words.append(corrected_word)\n",
    "\n",
    "# Join the corrected words back into a string\n",
    "corrected_text = ' '.join(corrected_words)\n",
    "\n",
    "# Save the corrected text to a new file\n",
    "output_file_path = 'transcriptions2_corrected_test1.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(corrected_text)\n",
    "\n",
    "print(\"Corrected text saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637b0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.23635285260380087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Read the transcribed audio text from the file\n",
    "transcribed_audio_file_path = 'transcriptions2_nostop_corrected.txt'\n",
    "with open(transcribed_audio_file_path, 'r') as file:\n",
    "    transcribed_audio_text = file.read()\n",
    "\n",
    "# Given input text\n",
    "input_text = \"human\"\n",
    "\n",
    "# Preprocess the text: tokenize and vectorize\n",
    "vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "\n",
    "# Compute the cosine similarity between the two texts\n",
    "cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "\n",
    "# Print the cosine similarity score\n",
    "print(\"Cosine Similarity Score:\", cosine_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478a1855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro-Winkler Similarity Score: 0.5334493560737905\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "\n",
    "# Calculate Jaro-Winkler similarity\n",
    "jaro_winkler_sim = jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "\n",
    "# Print Jaro-Winkler similarity score\n",
    "print(\"Jaro-Winkler Similarity Score:\", jaro_winkler_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc3ca2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# import string\n",
    "# from textblob import TextBlob\n",
    "# import enchant\n",
    "\n",
    "# # Download NLTK resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# # Load the transcribed text from the file\n",
    "# file_path = 'transcriptions2.txt'\n",
    "# with open(file_path, 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Phase 1: Tokenization\n",
    "# words = word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a93073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phase 2: Spell Checking and Correction using TextBlob\n",
    "# corrected_words = [str(TextBlob(word).correct()) for word in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c4832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Phase 3: Stopword Removal and Punctuation using NLTK\n",
    "# english_stopwords = set(stopwords.words('english'))\n",
    "# punctuation = set(string.punctuation)\n",
    "# filtered_words = [word for word in corrected_words if word.lower() not in english_stopwords.union(punctuation)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a169954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langdetect import detect\n",
    "\n",
    "# # Phase 4: Remove non-English words using langdetect\n",
    "# filtered_words_en = []\n",
    "\n",
    "# for word in filtered_words:\n",
    "#     try:\n",
    "#         if detect(word) == 'en':\n",
    "#             filtered_words_en.append(word)\n",
    "#     except:\n",
    "#         # Handle the case when language detection fails\n",
    "#         pass\n",
    "\n",
    "# filtered_words = filtered_words_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a04dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text saved to: preprocessed_text_3.txt\n"
     ]
    }
   ],
   "source": [
    "# # Join the filtered words back into a string\n",
    "# filtered_text = ' '.join(corrected_words)\n",
    "\n",
    "# # Save the filtered text to a new file\n",
    "# output_file_path = 'preprocessed_text_3.txt'\n",
    "# with open(output_file_path, 'w') as file:\n",
    "#     file.write(filtered_text)\n",
    "\n",
    "# print(\"Preprocessed text saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a79e2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count: 3513\n"
     ]
    }
   ],
   "source": [
    "# # Loading the preprocessed text file - 1\n",
    "# file_path = 'transcriptions2_corrected_test1.txt'\n",
    "# with open(file_path, 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Split the text into words\n",
    "# words = text.split()\n",
    "\n",
    "# # Calculate the word count\n",
    "# word_count = len(words)\n",
    "# print(\"Word Count:\", word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a5da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Word Count: 1182\n"
     ]
    }
   ],
   "source": [
    "# # Calculate the unique word count\n",
    "# unique_words = set(words)\n",
    "# unique_word_count = len(unique_words)\n",
    "# print(\"Unique Word Count:\", unique_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e00535",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Failed. modifying to find out which phase is causing failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c43f7ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count: 3724\n"
     ]
    }
   ],
   "source": [
    "# # Loading the preprocessed text file -2 \n",
    "# file_path = 'preprocessed_text_3.txt'\n",
    "# with open(file_path, 'r') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # Split the text into words\n",
    "# words = text.split()\n",
    "\n",
    "# # Calculate the word count\n",
    "# word_count = len(words)\n",
    "# print(\"Word Count:\", word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "578df8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Word Count: 87\n"
     ]
    }
   ],
   "source": [
    "# # Calculate the unique word count\n",
    "# unique_words = set(words)\n",
    "# unique_word_count = len(unique_words)\n",
    "# print(\"Unique Word Count:\", unique_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c181a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.0\n",
      "Jaro-Winkler Similarity Score: 0.583426151525699\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define file paths\n",
    "#input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\n",
    "#output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\n",
    "audio_file_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Audio\\01.wav'\n",
    "output_file = \"transcriptions2.txt\"\n",
    "output_file_path = 'transcriptions2_test1.txt'\n",
    "filtered_text_file_path = 'transcriptions2.txt'\n",
    "output_file_path_corrected = 'transcriptions2_corrected_test1.txt'\n",
    "transcribed_audio_file_path = 'transcriptions2_nostop_corrected.txt'\n",
    "\n",
    "\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "\n",
    "def transcribe_audio_batch(audio_file_path, batch_size=10, chunk_size=5, interval=10):\n",
    "    \"\"\"Transcribes audio in batches using Wav2Vec2.\"\"\"\n",
    "    wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        input_values = wav2vec2_processor(batch, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "        logits = wav2vec2_model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "        batch_transcriptions = wav2vec2_processor.batch_decode(predicted_ids)\n",
    "        transcriptions.extend(batch_transcriptions)\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "\n",
    "def optimize_text(file_path, output_file_path):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(filtered_text)\n",
    "\n",
    "\n",
    "def correct_spelling(filtered_text_file_path, output_file_path_corrected):\n",
    "    \"\"\"Corrects spelling errors in the filtered text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    with open(filtered_text_file_path, 'r') as file:\n",
    "        filtered_text = file.read()\n",
    "\n",
    "    filtered_words = filtered_text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "\n",
    "    with open(output_file_path_corrected, 'w') as file:\n",
    "        file.write(corrected_text)\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(transcribed_audio_file_path, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    with open(transcribed_audio_file_path, 'r') as file:\n",
    "        transcribed_audio_text = file.read()\n",
    "\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "\n",
    "def calculate_jaro_winkler_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates Jaro-Winkler similarity between transcribed audio text and input text.\"\"\"\n",
    "    return jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "\n",
    "\n",
    "# Convert video to audio\n",
    "convert_video_to_audio(input_video_path, output_audio_path)\n",
    "\n",
    "# Transcribe audio\n",
    "transcriptions = transcribe_audio_batch(audio_file_path)\n",
    "transcriptions_text = \"\".join(transcriptions)\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(transcriptions_text)\n",
    "\n",
    "# Optimize transcribed text\n",
    "optimize_text(output_file, output_file_path)\n",
    "\n",
    "# Correct spelling errors\n",
    "correct_spelling(output_file_path, output_file_path_corrected)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "input_text = \"java\"\n",
    "cosine_sim = calculate_cosine_similarity(transcribed_audio_file_path, input_text)\n",
    "print(\"Cosine Similarity Score:\", cosine_sim)\n",
    "\n",
    "# Calculate Jaro-Winkler similarity\n",
    "jaro_winkler_sim = calculate_jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "print(\"Jaro-Winkler Similarity Score:\", jaro_winkler_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f67c373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.04924017762579185\n"
     ]
    }
   ],
   "source": [
    "input_text = \"AI\"\n",
    "cosine_sim = calculate_cosine_similarity(transcribed_audio_file_path, input_text)\n",
    "print(\"Cosine Similarity Score:\", cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d424218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaro-Winkler Similarity Score: 0.5556251691998298\n"
     ]
    }
   ],
   "source": [
    "input_text = \"you\"\n",
    "\n",
    "# Calculate Jaro-Winkler similarity\n",
    "jaro_winkler_sim = calculate_jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "print(\"Jaro-Winkler Similarity Score:\", jaro_winkler_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4125f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Score: 0.0\n",
      "Jaro-Winkler Similarity Score: 0.583426151525699\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import concurrent.futures\n",
    "\n",
    "# Define file paths\n",
    "audio_file_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Audio\\01.wav'\n",
    "output_file = \"transcriptions2.txt\"\n",
    "output_file_path = 'transcriptions2_test1.txt'\n",
    "filtered_text_file_path = 'transcriptions2.txt'\n",
    "output_file_path_corrected = 'transcriptions2_corrected_test1.txt'\n",
    "transcribed_audio_file_path = 'transcriptions2_nostop_corrected.txt'\n",
    "\n",
    "# Define video and audio conversion paths\n",
    "input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\n",
    "output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\n",
    "\n",
    "\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def transcribe_audio_parallel(audio_file_path, batch_size=10, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "\n",
    "def optimize_text(file_path, output_file_path):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(filtered_text)\n",
    "\n",
    "\n",
    "def correct_spelling(filtered_text_file_path, output_file_path_corrected):\n",
    "    \"\"\"Corrects spelling errors in the filtered text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    with open(filtered_text_file_path, 'r') as file:\n",
    "        filtered_text = file.read()\n",
    "\n",
    "    filtered_words = filtered_text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "\n",
    "    with open(output_file_path_corrected, 'w') as file:\n",
    "        file.write(corrected_text)\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(transcribed_audio_file_path, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    with open(transcribed_audio_file_path, 'r') as file:\n",
    "        transcribed_audio_text = file.read()\n",
    "\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "\n",
    "def calculate_jaro_winkler_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates Jaro-Winkler similarity between transcribed audio text and input text.\"\"\"\n",
    "    return jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "\n",
    "\n",
    "# Convert video to audio\n",
    "convert_video_to_audio(input_video_path, output_audio_path)\n",
    "\n",
    "# Transcribe audio in parallel\n",
    "transcriptions = transcribe_audio_parallel(audio_file_path)\n",
    "\n",
    "# Write transcriptions to file\n",
    "transcriptions_text = \"\".join(transcriptions)\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(transcriptions_text)\n",
    "\n",
    "# Optimize transcribed text\n",
    "optimize_text(output_file, output_file_path)\n",
    "\n",
    "# Correct spelling errors\n",
    "correct_spelling(output_file_path, output_file_path_corrected)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "input_text = \"java\"\n",
    "cosine_sim = calculate_cosine_similarity(transcribed_audio_file_path, input_text)\n",
    "print(\"Cosine Similarity Score:\", cosine_sim)\n",
    "\n",
    "# Calculate Jaro-Winkler similarity\n",
    "jaro_winkler_sim = calculate_jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "print(\"Jaro-Winkler Similarity Score:\", jaro_winkler_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0280d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(transcriptions_text)\n\u001b[0;32m    100\u001b[0m optimized_text \u001b[38;5;241m=\u001b[39m optimize_text(transcriptions_text)\n\u001b[1;32m--> 101\u001b[0m corrected_text \u001b[38;5;241m=\u001b[39m \u001b[43mcorrect_spelling\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimized_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    103\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(corrected_text)\n",
      "Cell \u001b[1;32mIn [1], line 66\u001b[0m, in \u001b[0;36mcorrect_spelling\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     64\u001b[0m spell \u001b[38;5;241m=\u001b[39m SpellChecker()\n\u001b[0;32m     65\u001b[0m filtered_words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m---> 66\u001b[0m corrected_words \u001b[38;5;241m=\u001b[39m [spell\u001b[38;5;241m.\u001b[39mcorrection(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m filtered_words \u001b[38;5;28;01mif\u001b[39;00m spell\u001b[38;5;241m.\u001b[39mcorrection(word) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     67\u001b[0m corrected_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(corrected_words)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corrected_text\n",
      "Cell \u001b[1;32mIn [1], line 66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     64\u001b[0m spell \u001b[38;5;241m=\u001b[39m SpellChecker()\n\u001b[0;32m     65\u001b[0m filtered_words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m---> 66\u001b[0m corrected_words \u001b[38;5;241m=\u001b[39m [\u001b[43mspell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m filtered_words \u001b[38;5;28;01mif\u001b[39;00m spell\u001b[38;5;241m.\u001b[39mcorrection(word) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     67\u001b[0m corrected_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(corrected_words)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m corrected_text\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:158\u001b[0m, in \u001b[0;36mSpellChecker.correction\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"The most probable correct spelling for the word\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m    word (str): The word to correct\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    str: The most likely candidate or None if no correction is present\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m word \u001b[38;5;241m=\u001b[39m ensure_unicode(word)\n\u001b[1;32m--> 158\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidates:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:185\u001b[0m, in \u001b[0;36mSpellChecker.candidates\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# if still not found, use the edit distance 1 to calc edit distance 2\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 185\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__edit_distance_alt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tmp:\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tmp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36mSpellChecker.__edit_distance_alt\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknown(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medit_distance_1(e1))]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:252\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    251\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)]\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknown\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medit_distance_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:199\u001b[0m, in \u001b[0;36mSpellChecker.known\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    197\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    198\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words]\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word_frequency\u001b[38;5;241m.\u001b[39mdictionary \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:199\u001b[0m, in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    197\u001b[0m tmp_words \u001b[38;5;241m=\u001b[39m [ensure_unicode(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m    198\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m w\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp_words]\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tmp \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_word_frequency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdictionary\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_if_should_check(w)}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spellchecker\\spellchecker.py:328\u001b[0m, in \u001b[0;36mWordFrequency.dictionary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    325\u001b[0m     key \u001b[38;5;241m=\u001b[39m ensure_unicode(key)\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dictionary\u001b[38;5;241m.\u001b[39mpop(key \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_case_sensitive \u001b[38;5;28;01melse\u001b[39;00m key\u001b[38;5;241m.\u001b[39mlower(), default)\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdictionary\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124;03m\"\"\"Counter: A counting dictionary of all words in the corpus and the number\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    of times each has been seen\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m        Not settable\"\"\"\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dictionary\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define file paths\n",
    "audio_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Audio'\n",
    "output_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Output'\n",
    "\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription\n",
    "\n",
    "def transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "def optimize_text(text):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling errors in the text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "    filtered_words = text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text\n",
    "\n",
    "def calculate_cosine_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "def calculate_jaro_winkler_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates Jaro-Winkler similarity between transcribed audio text and input text.\"\"\"\n",
    "    return jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load pre-trained Wav2Vec2 model and processor\n",
    "    wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "    # Convert video to audio\n",
    " #   input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\n",
    " #   output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\n",
    " #   convert_video_to_audio(input_video_path, output_audio_path)\n",
    "\n",
    "    # Transcribe and process each audio file in parallel\n",
    "    for audio_file in os.listdir(audio_directory):\n",
    "        if audio_file.endswith('.wav'):\n",
    "            audio_file_path = os.path.join(audio_directory, audio_file)\n",
    "            transcriptions = transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model)\n",
    "            transcriptions_text = \"\".join(transcriptions)\n",
    "            output_file = os.path.join(output_directory, f\"{os.path.splitext(audio_file)[0]}_transcription.txt\")\n",
    "            with open(output_file, \"w\") as file:\n",
    "                file.write(transcriptions_text)\n",
    "            optimized_text = optimize_text(transcriptions_text)\n",
    "            corrected_text = correct_spelling(optimized_text)\n",
    "            with open(output_file, \"w\") as file:\n",
    "                file.write(corrected_text)\n",
    "            input_text = \"state space search\"  # Example input text for similarity calculation\n",
    "            cosine_sim = calculate_cosine_similarity(corrected_text, input_text)\n",
    "            jaro_winkler_sim = calculate_jaro_winkler_similarity(corrected_text, input_text)\n",
    "            print(f\"File: {audio_file}, Cosine Similarity: {cosine_sim}, Jaro-Winkler Similarity: {jaro_winkler_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1258d40",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Load pre-trained Wav2Vec2 model and processor\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     wav2vec2_processor \u001b[38;5;241m=\u001b[39m Wav2Vec2Processor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/wav2vec2-base-960h\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m     wav2vec2_model \u001b[38;5;241m=\u001b[39m \u001b[43mWav2Vec2ForCTC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/wav2vec2-base-960h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate space search\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Example input text for similarity calculation\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Convert video to audio\u001b[39;00m\n\u001b[0;32m     88\u001b[0m  \u001b[38;5;66;03m#   input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\u001b[39;00m\n\u001b[0;32m     89\u001b[0m  \u001b[38;5;66;03m#   output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\u001b[39;00m\n\u001b[0;32m     90\u001b[0m  \u001b[38;5;66;03m#   convert_video_to_audio(input_video_path, output_audio_path)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# Transcribe and process each audio file in parallel\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:3850\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3841\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3842\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3843\u001b[0m     (\n\u001b[0;32m   3844\u001b[0m         model,\n\u001b[0;32m   3845\u001b[0m         missing_keys,\n\u001b[0;32m   3846\u001b[0m         unexpected_keys,\n\u001b[0;32m   3847\u001b[0m         mismatched_keys,\n\u001b[0;32m   3848\u001b[0m         offload_index,\n\u001b[0;32m   3849\u001b[0m         error_msgs,\n\u001b[1;32m-> 3850\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3857\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3858\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3861\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3862\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3866\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3868\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   3869\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   4215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4216\u001b[0m     \u001b[38;5;66;03m# Whole checkpoint\u001b[39;00m\n\u001b[0;32m   4217\u001b[0m     mismatched_keys \u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[0;32m   4218\u001b[0m         state_dict,\n\u001b[0;32m   4219\u001b[0m         model_state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4223\u001b[0m         ignore_mismatched_sizes,\n\u001b[0;32m   4224\u001b[0m     )\n\u001b[1;32m-> 4225\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4226\u001b[0m     offload_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4228\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n\u001b[0;32m   4229\u001b[0m \n\u001b[0;32m   4230\u001b[0m     \u001b[38;5;66;03m# This should always be a list but, just to be sure.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:627\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 627\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:625\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:625\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 625 (3 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:625\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:621\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    619\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2042\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhile copying the parameter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2043\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the model are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2044\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the checkpoint are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_param\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2045\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man exception occurred : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m                       )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define file paths\n",
    "audio_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Audio'\n",
    "output_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Output'\n",
    "\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription\n",
    "\n",
    "def transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "def optimize_text(text):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling errors in the text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "    filtered_words = text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text\n",
    "\n",
    "def calculate_cosine_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "def calculate_jaro_winkler_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates Jaro-Winkler similarity between transcribed audio text and input text.\"\"\"\n",
    "    return jaro_winkler_similarity(transcribed_audio_text, input_text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load pre-trained Wav2Vec2 model and processor\n",
    "    wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    input_text = \"state space search\"  # Example input text for similarity calculation\n",
    "\n",
    "    # Convert video to audio\n",
    " #   input_video_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\test2.mp4'\n",
    " #   output_audio_path = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Audio_Data\\audio2.wav'\n",
    " #   convert_video_to_audio(input_video_path, output_audio_path)\n",
    "\n",
    "    # Transcribe and process each audio file in parallel\n",
    "    for audio_file in os.listdir(audio_directory):\n",
    "        if audio_file.endswith('.wav'):\n",
    "            audio_file_path = os.path.join(audio_directory, audio_file)\n",
    "            output_file = os.path.join(output_directory, f\"{os.path.splitext(audio_file)[0]}_transcription.txt\")\n",
    "\n",
    "            # Check if transcription file already exists\n",
    "            if not os.path.exists(output_file):\n",
    "                transcriptions = transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model)\n",
    "                transcriptions_text = \"\".join(transcriptions)\n",
    "                with open(output_file, \"w\") as file:\n",
    "                    file.write(transcriptions_text)\n",
    "                optimized_text = optimize_text(transcriptions_text)\n",
    "                corrected_text = correct_spelling(optimized_text)\n",
    "                with open(output_file, \"w\") as file:\n",
    "                    file.write(corrected_text)\n",
    "                cosine_sim = calculate_cosine_similarity(corrected_text, input_text)\n",
    "                jaro_winkler_sim = calculate_jaro_winkler_similarity(corrected_text, input_text)\n",
    "                print(f\"File: {audio_file}, Cosine Similarity: {cosine_sim}, Jaro-Winkler Similarity: {jaro_winkler_sim}\")\n",
    "            else:\n",
    "                print(f\"Transcription file already exists for {audio_file}. Skipping transcription.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b5f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\02\\02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\03\\03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\04\\04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\05\\05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\06\\06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\07\\07.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\09\\09.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\11\\11.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\audio_KBVRS\\29\\29.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Transcription file already exists for 01.mp4. Skipping transcription.\n",
      "Video: 02.mp4, Cosine Similarity: 0.0\n",
      "Video: 03.mp4, Cosine Similarity: 0.004349470810331771\n",
      "Video: 04.mp4, Cosine Similarity: 0.0\n",
      "Video: 05.mp4, Cosine Similarity: 0.0\n",
      "Video: 06.mp4, Cosine Similarity: 0.0\n",
      "Video: 07.mp4, Cosine Similarity: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import librosa\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Define the directory containing the videos\n",
    "video_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL\\Video'\n",
    "\n",
    "# Define the parent directory where the audio and transcriptions will be stored\n",
    "parent_audio_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\NPTEL'\n",
    "\n",
    "# Define the reference text for similarity calculation\n",
    "input_text = \"linear regression\"  \n",
    "\n",
    "# Load pre-trained Wav2Vec2 model and processor\n",
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Function to convert video to audio\n",
    "def convert_video_to_audio(input_video_path, output_audio_path):\n",
    "    \"\"\"Converts a video file to audio.\"\"\"\n",
    "    video_clip = VideoFileClip(input_video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    audio_clip.write_audiofile(output_audio_path)\n",
    "    video_clip.close()\n",
    "\n",
    "# Function to transcribe audio chunks\n",
    "def transcribe_chunk(chunk, wav2vec2_processor, wav2vec2_model):\n",
    "    \"\"\"Transcribe a chunk of audio.\"\"\"\n",
    "    input_values = wav2vec2_processor(chunk, sampling_rate=16000, return_tensors=\"pt\", padding=True).input_values\n",
    "    logits = wav2vec2_model(input_values).logits\n",
    "    transcription = wav2vec2_processor.batch_decode(torch.argmax(logits, dim=-1))\n",
    "    return transcription\n",
    "\n",
    "# Function to transcribe audio in parallel\n",
    "def transcribe_audio_parallel(audio_file_path, wav2vec2_processor, wav2vec2_model, chunk_size=5):\n",
    "    \"\"\"Transcribe audio in parallel using Wav2Vec2.\"\"\"\n",
    "    audio_input, _ = librosa.load(audio_file_path, sr=16000)\n",
    "    chunks = [audio_input[i:i + chunk_size * 16000] for i in range(0, len(audio_input), chunk_size * 16000)]\n",
    "    transcriptions = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(transcribe_chunk, chunk, wav2vec2_processor, wav2vec2_model): chunk\n",
    "                           for chunk in chunks}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "            try:\n",
    "                transcription = future.result()\n",
    "                transcriptions.extend(transcription)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "\n",
    "    return transcriptions\n",
    "\n",
    "# Function to optimize transcribed text\n",
    "def optimize_text(text):\n",
    "    \"\"\"Optimizes transcribed text by removing stopwords and punctuation.\"\"\"\n",
    "    words = word_tokenize(text)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    all_stopwords = english_stopwords.union(punctuation)\n",
    "    filtered_words = [word for word in words if word.lower() not in all_stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "\n",
    "# Function to correct spelling errors\n",
    "def correct_spelling(text):\n",
    "    \"\"\"Corrects spelling errors in the text.\"\"\"\n",
    "    spell = SpellChecker()\n",
    "    filtered_words = text.split()\n",
    "    corrected_words = [spell.correction(word) for word in filtered_words if spell.correction(word) is not None]\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(transcribed_audio_text, input_text):\n",
    "    \"\"\"Calculates cosine similarity between transcribed audio text and input text.\"\"\"\n",
    "    vectorizer = CountVectorizer().fit([transcribed_audio_text, input_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_audio_text, input_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Convert video to audio\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            audio_directory = os.path.join(parent_audio_directory, 'audio_KBVRS', os.path.splitext(video_file)[0])\n",
    "            audio_path = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '.wav')\n",
    "            transcription_file = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '_transcription.txt')\n",
    "\n",
    "            # Check if transcription directory already exists\n",
    "            if not os.path.exists(audio_directory):\n",
    "                os.makedirs(audio_directory)\n",
    "\n",
    "                # Convert video to audio\n",
    "                convert_video_to_audio(video_path, audio_path)\n",
    "\n",
    "    # Transcribe audio\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith('.mp4'):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            audio_directory = os.path.join(parent_audio_directory, 'audio_KBVRS', os.path.splitext(video_file)[0])\n",
    "            audio_path = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '.wav')\n",
    "            transcription_file = os.path.join(audio_directory, os.path.splitext(video_file)[0] + '_transcription.txt')\n",
    "\n",
    "            # Check if transcription file already exists\n",
    "            if not os.path.exists(transcription_file):\n",
    "                # Transcribe audio\n",
    "                transcriptions = transcribe_audio_parallel(audio_path, wav2vec2_processor, wav2vec2_model)\n",
    "                transcriptions_text = \"\".join(transcriptions)\n",
    "\n",
    "                # Write transcribed text to file\n",
    "                with open(transcription_file, \"w\") as file:\n",
    "                    file.write(transcriptions_text)\n",
    "\n",
    "                # Optimize text and correct spelling\n",
    "                optimized_text = optimize_text(transcriptions_text)\n",
    "                corrected_text = correct_spelling(optimized_text)\n",
    "\n",
    "                # Calculate cosine similarity\n",
    "                cosine_sim = calculate_cosine_similarity(corrected_text, input_text)\n",
    "\n",
    "                print(f\"Video: {video_file}, Cosine Similarity: {cosine_sim}\")\n",
    "\n",
    "                # Hide the directory\n",
    "                if os.name == 'nt':  # Windows\n",
    "                    ctypes.windll.kernel32.SetFileAttributesW(audio_directory, 2)  # 2 is the code for hidden attribute\n",
    "                else:  # Unix-like\n",
    "                    os.rename(audio_directory, os.path.join(os.path.dirname(audio_directory), '.' + os.path.basename(audio_directory)))\n",
    "            else:\n",
    "                print(f\"Transcription file already exists for {video_file}. Skipping transcription.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b141555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4874ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 01_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5102029545005805\n",
      "File: 02_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5296761915218724\n",
      "File: 03_transcription.txt, Cosine Similarity: 0.004343804386977241, Jaro-Winkler Similarity: 0.529726614504008\n",
      "File: 04_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5298460918819893\n",
      "File: 05_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5101395251615599\n",
      "File: 06_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5100472828169275\n",
      "File: 07_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5494827978600301\n",
      "File: 09_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5102529798669606\n",
      "File: 11_transcription.txt, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.510345047109753\n",
      "File: 29_transcription.txt, Cosine Similarity: 0.4908236132007333, Jaro-Winkler Similarity: 0.510253764123733\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.metrics.distance import jaro_winkler_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the directory containing the transcribed text files\n",
    "transcribed_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Output'\n",
    "\n",
    "# Reference text for similarity calculation\n",
    "reference_text = \"linear regression\"\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(transcribed_text, reference_text):\n",
    "    vectorizer = CountVectorizer().fit([transcribed_text, reference_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_text, reference_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "# Function to calculate Jaro-Winkler similarity\n",
    "def calculate_jaro_winkler_similarity(transcribed_text, reference_text):\n",
    "    return jaro_winkler_similarity(transcribed_text, reference_text)\n",
    "\n",
    "# Iterate through each text file in the directory\n",
    "for filename in os.listdir(transcribed_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(transcribed_directory, filename)\n",
    "        \n",
    "        # Read the content of the text file\n",
    "        with open(file_path, 'r') as file:\n",
    "            transcribed_text = file.read()\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        cosine_sim = calculate_cosine_similarity(transcribed_text, reference_text)\n",
    "        \n",
    "        # Calculate Jaro-Winkler similarity\n",
    "        jaro_winkler_sim = calculate_jaro_winkler_similarity(transcribed_text, reference_text)\n",
    "\n",
    "        # Print or store the similarity scores\n",
    "        print(f\"File: {filename}, Cosine Similarity: {cosine_sim}, Jaro-Winkler Similarity: {jaro_winkler_sim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7caa0a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Analysis based on Cosine Similarity:\n",
      "File: 29_transcription.txt, Cosine Similarity: 0.4908236132007333\n",
      "File: 03_transcription.txt, Cosine Similarity: 0.004343804386977241\n",
      "File: 01_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 02_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 04_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 05_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 06_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 07_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 09_transcription.txt, Cosine Similarity: 0.0\n",
      "File: 11_transcription.txt, Cosine Similarity: 0.0\n",
      "----------------------------------------------------------------------------------------------\n",
      "Video File: D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\29_transcription.mp4\n",
      "Video File: D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video\\03_transcription.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the directory containing the transcribed text files\n",
    "transcribed_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Output'\n",
    "\n",
    "# Reference text for similarity calculation\n",
    "reference_text = \"linear regression\"\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def calculate_cosine_similarity(transcribed_text, reference_text):\n",
    "    vectorizer = CountVectorizer().fit([transcribed_text, reference_text])\n",
    "    vectorized_text = vectorizer.transform([transcribed_text, reference_text])\n",
    "    cosine_sim = cosine_similarity(vectorized_text)[0][1]\n",
    "    return cosine_sim\n",
    "\n",
    "# List to store similarity scores along with filenames\n",
    "similarity_scores = []\n",
    "\n",
    "# Iterate through each text file in the directory\n",
    "for filename in os.listdir(transcribed_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(transcribed_directory, filename)\n",
    "        \n",
    "        # Read the content of the text file\n",
    "        with open(file_path, 'r') as file:\n",
    "            transcribed_text = file.read()\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        cosine_sim = calculate_cosine_similarity(transcribed_text, reference_text)\n",
    "\n",
    "        # Append the filename and cosine similarity score to the list\n",
    "        similarity_scores.append((filename, cosine_sim))\n",
    "\n",
    "# Sort the list of similarity scores based on cosine similarity\n",
    "similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted results based on cosine similarity\n",
    "print(\"Similarity Analysis based on Cosine Similarity:\")\n",
    "for filename, cosine_sim in similarity_scores:\n",
    "    print(f\"File: {filename}, Cosine Similarity: {cosine_sim}\")\n",
    "\n",
    "# Original video directory\n",
    "video_directory = r'D:\\SRM\\3rd_Year\\6th_Semester\\Research\\Video_Retriveal_System\\Data\\Video'\n",
    "print('----------------------------------------------------------------------------------------------')\n",
    "# Iterate through the sorted similarity scores\n",
    "for filename, cosine_sim in similarity_scores:\n",
    "    # Exclude files with cosine similarity of 0\n",
    "    if cosine_sim > 0:\n",
    "        # Construct the filenames for video, audio, and transcribed text\n",
    "        video_filename = os.path.join(video_directory, os.path.splitext(filename)[0] + '.mp4')\n",
    "\n",
    "        # Print or use the filenames as needed\n",
    "        print(\"Video File:\", video_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c58b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314348d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # File: 01.wav, Cosine Similarity: 0.005799075005326842, Jaro-Winkler Similarity: 0.5189410239758807 \n",
    "# File: 02.wav, Cosine Similarity: 0.1521350346886033, Jaro-Winkler Similarity: 0.5187984998530961\n",
    "# File: 03.wav, Cosine Similarity: 0.3262965315770913, Jaro-Winkler Similarity: 0.5373704074115231\n",
    "# File: 04.wav, Cosine Similarity: 0.10446634907830515, Jaro-Winkler Similarity: 0.6299975302964496\n",
    "# File: 05.wav, Cosine Similarity: 0.2771044236587905, Jaro-Winkler Similarity: 0.5003553449807521\n",
    "# File: 06.wav, Cosine Similarity: 0.09556226218669801, Jaro-Winkler Similarity: 0.5372947136528841\n",
    "# File: 07.wav, Cosine Similarity: 0.051082332851447504, Jaro-Winkler Similarity: 0.5375274735255118\n",
    "# File: 09.wav, Cosine Similarity: 0.07073958731981543, Jaro-Winkler Similarity: 0.5560310290479082\n",
    "# Error processing chunk: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size\n",
    "# File: 11.wav, Cosine Similarity: 0.0, Jaro-Winkler Similarity: 0.5190914749738279\n",
    "# File: 29.wav, Cosine Similarity: 0.004828383156831224, Jaro-Winkler Similarity: 0.5375133409189137"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
